{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nb71a51734eb64b6298fd089ebceb222b (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD, SKOS, DCTERMS\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Helper function to clean and format strings for URIs\n",
    "def clean_for_uri(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "    a, b = 'áéíóúüñÁÉÍÓÚÜÑ', 'aeiouunAEIOUUN'\n",
    "    trans = str.maketrans(a, b)\n",
    "    text = text.translate(trans)\n",
    "    text = re.sub(r'[<>:\"/\\\\|?*(){}[\\].,;\\']', '', text)\n",
    "    text = re.sub(r'\\s+', '_', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9_-]', '', text)\n",
    "    return text.lower()[:100]\n",
    "\n",
    "def clean_for_uri_country(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "    a, b = 'áéíóúüñÁÉÍÓÚÜÑ', 'aeiouunAEIOUUN'\n",
    "    trans = str.maketrans(a, b)\n",
    "    text = text.translate(trans)\n",
    "    text = re.sub(r'[<>:\"/\\\\|?*(){}[\\].,;\\']', '', text)\n",
    "    text = re.sub(r'\\s+', '_', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9_-]', '', text)\n",
    "    return text.title()[:100]\n",
    "\n",
    "# Namespaces\n",
    "g = Graph()\n",
    "schema = Namespace(\"https://schema.org/\")\n",
    "dbp = Namespace(\"http://dbpedia.org/resource/\")\n",
    "myv = Namespace(\"http://example.org/myv/\")\n",
    "ex = Namespace(\"http://example.org/sa/\")  # Nueva URI base con 'sa'\n",
    "sko = SKOS\n",
    "g.bind(\"schema\", schema)\n",
    "g.bind(\"dbp\", dbp)\n",
    "g.bind(\"myv\", myv)\n",
    "g.bind(\"ex\", ex)  # Enlazar la nueva URI base\n",
    "g.bind(\"skos\", sko)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "\n",
    "# Load CSVs\n",
    "citations_df = pd.read_csv('citations.csv')\n",
    "datos_con_referencias_df = pd.read_csv('scopus_detailed_papers.csv')\n",
    "scopus_papers_df = pd.read_csv('scopus_papers.csv')\n",
    "\n",
    "# Add Countries and Cities\n",
    "locations = scopus_papers_df[['affiliation_country', 'affiliation_city']].dropna().drop_duplicates()\n",
    "for _, row in locations.iterrows():\n",
    "    countries = [country.strip() for country in row['affiliation_country'].split(';')]\n",
    "    cities = [city.strip() for city in row['affiliation_city'].split(';')]\n",
    "    for country, city in zip(countries, cities):\n",
    "        country_uri = URIRef(ex + clean_for_uri_country(country))\n",
    "        city_uri = URIRef(ex + clean_for_uri_country(city))\n",
    "        g.add((country_uri, RDF.type, schema.Country))\n",
    "        g.add((country_uri, schema.name, Literal(country)))\n",
    "        g.add((city_uri, RDF.type, schema.City))\n",
    "        g.add((city_uri, schema.name, Literal(city)))\n",
    "        g.add((city_uri, schema.containsPlace, country_uri))\n",
    "\n",
    "# Add Organizations and link to cities\n",
    "organizations = scopus_papers_df[['affilname', 'affiliation_city', 'affiliation_country']].dropna().drop_duplicates()\n",
    "for _, row in organizations.iterrows():\n",
    "    org_uri = URIRef(ex + clean_for_uri(row['affilname']))\n",
    "    cities = [city.strip() for city in row['affiliation_city'].split(';')]\n",
    "    countries = [country.strip() for country in row['affiliation_country'].split(';')]\n",
    "    g.add((org_uri, RDF.type, schema.Organization))\n",
    "    g.add((org_uri, schema.name, Literal(row['affilname'])))\n",
    "    for city, country in zip(cities, countries):\n",
    "        city_uri = URIRef(ex + clean_for_uri_country(city))\n",
    "        country_uri = URIRef(ex + clean_for_uri_country(country))\n",
    "        g.add((org_uri, schema.location, city_uri))\n",
    "        g.add((city_uri, schema.containsPlace, country_uri))       \n",
    "\n",
    "# Add Persons and their Affiliations\n",
    "for _, row in datos_con_referencias_df[['author_names', 'affilname', 'affiliation_city', 'affiliation_country']].dropna().iterrows():\n",
    "    authors = row['author_names'].split(';')\n",
    "    affiliations = row['affilname'].split(';')\n",
    "    cities = row['affiliation_city'].split(';')\n",
    "    countries = row['affiliation_country'].split(';')\n",
    "    \n",
    "    # Ensure all lists have the same length by truncating or padding with \"unknown\"\n",
    "    max_len = max(len(authors), len(affiliations), len(cities), len(countries))\n",
    "    authors += [\"unknown\"] * (max_len - len(authors))\n",
    "    affiliations += [\"unknown\"] * (max_len - len(affiliations))\n",
    "    cities += [\"unknown\"] * (max_len - len(cities))\n",
    "    countries += [\"unknown\"] * (max_len - len(countries))\n",
    "    \n",
    "    for author, affiliation, city, country in zip(authors, affiliations, cities, countries):\n",
    "        # Create URIs for each entity\n",
    "        author_uri = URIRef(ex + clean_for_uri(author.strip()))\n",
    "        org_uri = URIRef(ex + clean_for_uri(affiliation.strip()))\n",
    "        city_uri = URIRef(ex + clean_for_uri_country(city.strip()))\n",
    "        country_uri = URIRef(ex + clean_for_uri_country(country.strip()))\n",
    "        \n",
    "        # Add Person and their affiliation\n",
    "        g.add((author_uri, RDF.type, schema.Person))\n",
    "        g.add((author_uri, schema.name, Literal(author.strip())))\n",
    "        g.add((author_uri, schema.affiliation, org_uri))\n",
    "        \n",
    "        # Add Organization and its location\n",
    "        g.add((org_uri, RDF.type, schema.Organization))\n",
    "        g.add((org_uri, schema.name, Literal(affiliation.strip())))\n",
    "        g.add((org_uri, schema.location, city_uri))\n",
    "        \n",
    "        # Add City and its country\n",
    "        g.add((city_uri, RDF.type, schema.City))\n",
    "        g.add((city_uri, schema.name, Literal(city.strip())))\n",
    "        g.add((city_uri, schema.containsPlace, country_uri))\n",
    "        \n",
    "        # Add Country\n",
    "        g.add((country_uri, RDF.type, schema.Country))\n",
    "        g.add((country_uri, schema.name, Literal(country.strip())))\n",
    "\n",
    "# Add Keywords\n",
    "keywords = scopus_papers_df['authkeywords'].dropna().str.split('|').explode().str.strip().str.lower().drop_duplicates()\n",
    "for keyword in keywords:\n",
    "    concept_uri = URIRef(ex + clean_for_uri(keyword))  # Sin prefijo \"concept/\"\n",
    "    g.add((concept_uri, RDF.type, SKOS.Concept))\n",
    "    g.add((concept_uri, RDFS.label, Literal(keyword))) \n",
    "\n",
    "# Add Articles\n",
    "for _, row in scopus_papers_df.iterrows():\n",
    "    if pd.isna(row['doi']):\n",
    "        continue\n",
    "    article_uri = URIRef(ex + clean_for_uri(row['doi']))  # Sin prefijo \"article/\"\n",
    "    g.add((article_uri, RDF.type, schema.Article))\n",
    "    g.add((article_uri, schema.identifier, Literal(row['doi'])))\n",
    "    g.add((article_uri, schema.title, Literal(row['title'])))\n",
    "    if not pd.isna(row['description']):\n",
    "        g.add((article_uri, schema.description, Literal(row['description'])))\n",
    "    if not pd.isna(row['coverDate']):\n",
    "        g.add((article_uri, schema.datePublished, Literal(row['coverDate'], datatype=XSD.date)))\n",
    "    \n",
    "    # Reemplazar myv:citationCount por entidad de observación\n",
    "    if not pd.isna(row['citedby_count']):\n",
    "        observation_uri = URIRef(ex + clean_for_uri(row['doi'] + \"_citation_count\"))  # Sin prefijo \"observation/\"\n",
    "        g.add((observation_uri, RDF.type, myv.Observation))\n",
    "        g.add((observation_uri, schema.observationDate, Literal(\"2025-12-21\", datatype=XSD.date)))  # Fecha fija\n",
    "        g.add((observation_uri, schema.value, Literal(row['citedby_count'], datatype=XSD.integer)))\n",
    "        g.add((article_uri, schema.observation, observation_uri))\n",
    "    \n",
    "    if not pd.isna(row['authkeywords']):\n",
    "        for keyword in row['authkeywords'].split('|'):\n",
    "            concept_uri = URIRef(ex + clean_for_uri(keyword.strip().lower()))  # Sin prefijo \"concept/\"\n",
    "            g.add((article_uri, DCTERMS.subject, concept_uri))\n",
    "            \n",
    "    if not pd.isna(row['author_names']):\n",
    "        for author_name in row['author_names'].split(';'):\n",
    "            author_uri = URIRef(ex + clean_for_uri(author_name.strip()))  # Sin prefijo \"person/\"\n",
    "            g.add((author_uri, RDF.type, schema.Person))\n",
    "            g.add((author_uri, schema.name, Literal(author_name.strip())))\n",
    "            g.add((article_uri, schema.author, author_uri))\n",
    "\n",
    "# Add References as myv:Observation\n",
    "for _, row in citations_df.dropna(subset=['DOI', 'Paper DOI']).iterrows():\n",
    "    source_uri = URIRef(ex + clean_for_uri(row['DOI']))  # Sin prefijo \"article/\"\n",
    "    target_uri = URIRef(ex + clean_for_uri(row['Paper DOI']))  # Sin prefijo \"article/\"\n",
    "    observation_uri = URIRef(ex + clean_for_uri(row['DOI'] + \"_to_\" + row['Paper DOI']))  # Sin prefijo \"observation/\"\n",
    "    g.add((observation_uri, RDF.type, myv.Observation))\n",
    "    g.add((observation_uri, schema.citation, source_uri))\n",
    "    g.add((observation_uri, schema.citation, target_uri))\n",
    "\n",
    "# Serialize RDF to Turtle format\n",
    "g.serialize(\"articles_base_data.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
